import numpy as np
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
import matplotlib.pyplot as plt

data = {
    "shear": [2160.70, 1680.15, 2318.00, 2063.30, 2209.50, 1710.30,
             1786.70, 2577.00, 2359.90, 2258.70, 2167.20, 2401.55, 1781.80,
             2338.75, 1767.30, 2055.50, 2416.40, 2202.50, 2656.20, 1755.70 ],
    "age": [15.50, 23.75, 8.00, 17.00, 5.50, 19.00, 24.00, 2.50, 7.50,
           11.00, 13.00, 3.75, 25.00, 9.75, 22.00, 18.00, 6.00, 12.50, 2.00, 21.50]
}
print(data.items())
df = pd.DataFrame(data)
df.head()
Y = data['shear']
X = data['age']
X = sm.add_constant(X)
linear_regression = sm.OLS(Y, X)
fitted_model = linear_regression.fit()
fitted_model.summary()
intercept = fitted_model.params[0]
coefficient = fitted_model.params[1]
print(intercept)
print(coefficient)


import numpy as np

def gradient(X, Y, initial_learning_rate=0.01, decay_rate=0.01, n_iterations=1000):
    m = len(Y)
    theta = np.random.randn(X.shape[1])  
    for iteration in range(n_iterations):
        predictions = X.dot(theta)
        errors = predictions - Y
        gradients = (2/m) * X.T.dot(errors)
        learning_rate = initial_learning_rate / (1 + decay_rate * iteration)
        theta -= learning_rate * gradients
        
        error = np.mean(errors**2)
        
        if error < 0.1:
            break

    return theta



theta_gd = gradient(X, Y)
print("\nGradient descent result (theta):", theta_gd)






#OUTPUT
dict_items([('shear', [2160.7, 1680.15, 2318.0, 2063.3, 2209.5, 1710.3, 1786.7, 2577.0, 2359.9, 2258.7, 2167.2, 2401.55, 1781.8, 2338.75, 1767.3, 2055.5, 2416.4, 2202.5, 2656.2, 1755.7]), ('age', [15.5, 23.75, 8.0, 17.0, 5.5, 19.0, 24.0, 2.5, 7.5, 11.0, 13.0, 3.75, 25.0, 9.75, 22.0, 18.0, 6.0, 12.5, 2.0, 21.5])])
2629.822359001296
-37.15359094490524


Gradient descent result (theta): [ 9.62305884e+21 -5.50348397e+20]
